; This is a sample inventory demonstrating typical settings when using VMs on ESXi. RoCEv2 networking must
; use SR-IOV, configured on each VM against a Connect-X adapter's virtual functions.
; In this scenario, high-speed networking has already been pre-configured by a system administrator.
; To use the pre-allocated IP addresses, `tcp_ip_list` and `rocev2_ip_list` vars must be defined to describe the list of
; IP addresses on each host.
; IPV6 or IPV4 IPs are supported for TCP, and can be provided either as IP or hostname. RoCEv2 IPs must be IPV4.

[servers]
vm-host01.domain.com tcp_ip_list="['vm-host1-v6.domain.com']" rocev2_ip_list="['192.168.200.1']"
vm-host02.domain.com tcp_ip_list="['vm-host2-v6.domain.com']" rocev2_ip_list="['192.168.200.2']"
vm-host03.domain.com tcp_ip_list="['vm-host3-v6.domain.com']" rocev2_ip_list="['192.168.200.3']"
vm-host04.domain.com tcp_ip_list="['vm-host4-v6.domain.com']" rocev2_ip_list="['192.168.200.4']"
vm-host05.domain.com tcp_ip_list="['vm-host5-v6.domain.com']" rocev2_ip_list="['192.168.200.5']"
vm-host06.domain.com tcp_ip_list="['vm-host6-v6.domain.com']" rocev2_ip_list="['192.168.200.6']"
vm-host07.domain.com tcp_ip_list="['vm-host7-v6.domain.com']" rocev2_ip_list="['192.168.200.7']"
vm-host08.domain.com tcp_ip_list="['vm-host8-v6.domain.com']" rocev2_ip_list="['192.168.200.8']"
vm-host09.domain.com tcp_ip_list="['vm-host9-v6.domain.com']" rocev2_ip_list="['192.168.200.9']"
vm-host10.domain.com tcp_ip_list="['vm-host10-v6.domain.com']" rocev2_ip_list="['192.168.200.10']"

; In this scenario, the client will also be collocated with the server
[clients]
vm-host[01:10].domain.com

; The `ansible_user` var must be defined for the playbook to manage the hosts using a different user-id
; than you are currently logged in with.
; A `target_fw_version` must be defined, containing a space-separated list of values for each NVMe SSD to be
; allocated into NVMeOF subsystem storage on each host. On Vmware, Virtual NVMe firmware is always `1.0`.
; `dss_target_mode` must be set to `kv_block_vm` in virtual hosts with limited resources.
; Inbox infiniband drivers are explicitly defined here. If ommitted, Mellanox OFED will be installed instead.
; In order to use Datamover, a `datamover_nfs_shares` var must be defined describing a list of NFS servers and their available shares.
[all:vars]
ansible_user=ansible
target_fw_version=1.0
dss_target_mode=kv_block_vm
infiniband_driver=inbox
datamover_nfs_shares=[{'ip': 'msl-ssg-nfs-vm01-v6', 'shares': ['/mnt/nfs_share/20gb-01', '/mnt/nfs_share/20gb-02', '/mnt/nfs_share/20gb-03', '/mnt/nfs_share/20gb-04', '/mnt/nfs_share/20gb-05']},{'ip': 'msl-ssg-nfs-vm02-v6', 'shares': ['/mnt/nfs_share/20gb-06', '/mnt/nfs_share/20gb-07', '/mnt/nfs_share/20gb-08', '/mnt/nfs_share/20gb-09', '/mnt/nfs_share/20gb-10']}]
